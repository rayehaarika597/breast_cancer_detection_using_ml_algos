# -*- coding: utf-8 -*-
"""Copy of ai mini project final .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17iKtZwzEdc83cvt_ulOqaZMVA33Ua85g

numpy, pandas, matplotlib.pylot, and seaborn are all different libraries and we gave them “nicknames” such as “sns” for seabron, so we can refer to the seaborn library by using “sns”.
"""

# importing libraries
import numpy
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

"""Then, I’m going to load the kaggle data set that we downloaded"""

df=pd.read_csv("data.csv")

df.head()

df.info()

# return all the columns with null values count
df.isna().sum()

# return the size of dataset
df.shape

# remove the column
df=df.dropna(axis=1)

# shape of dataset after removing the null column
df.shape

# describe the dataset
df.describe()

# Get the count of malignant<M> and Benign<B> cells
df['diagnosis'].value_counts()

sns.countplot(df['diagnosis'],label="count")

# label encoding(convert the value of M and B into 1 and 0)
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)

"""Next, we imported label encoder from sklearn.preprocessing (sklearn is short for sci kit learn. We can think about it as sklearn is the library, preprosseing is the aisle and Label Encoder is the book)

- In the third line: “labelencoder_Y = LabelEncoder()”, we are “re-naimg” the book. From LabelEncoder() to labelencoder_Y. This doesn’t actually effect the output, but it’s for format purposes.

Break down of: “df.iloc[:,1]”

- df.iloc — loc is used to for data selcetion, and we put the i, because it stands for integer, and our data is in the form of integers. We put df. because it stands for data frame and we are selecting integers in our data frame.

- [:,1] — Think of this in terms of x and y coordinates (x,y). The y value is 1, and because of the colon, it refers to all the data in rows (x is horizontal). Therefore, this means we are looking at the first column for all our rows in the data set.


"""

df.head()

sns.pairplot(df.iloc[:,1:5],hue="diagnosis")

# get the correlation
df.iloc[:,1:32].corr()

# visualize the correlation
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:10].corr(),annot=True,fmt=".0%")

# split the dataset into dependent(X) and Independent(Y) datasets
X=df.iloc[:,2:31].values
Y=df.iloc[:,1].values

# spliting the data into trainning and test dateset
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.20,random_state=0)

# feature scaling
from sklearn.preprocessing import StandardScaler
X_train=StandardScaler().fit_transform(X_train)
X_test=StandardScaler().fit_transform(X_test)

# models/ Algorithms

def models(X_train,Y_train):
        #logistic regression
        from sklearn.linear_model import LogisticRegression
        log=LogisticRegression(random_state=0)
        log.fit(X_train,Y_train)
        
        
       
        
        #Random Forest
        from sklearn.ensemble import RandomForestClassifier
        forest=RandomForestClassifier(random_state=0,criterion="entropy",n_estimators=10)
        forest.fit(X_train,Y_train)
        
        print('[0]logistic regression accuracy:',log.score(X_train,Y_train))
       
        print('[1]Random forest accuracy:',forest.score(X_train,Y_train))
        
        return log,forest

model=models(X_train,Y_train)

#test model accuracy on test data on confusion matrix
from sklearn.metrics import confusion_matrix
for i in range( len(model) ):
   print('Model ', i)
   cm = confusion_matrix(Y_test, model[i].predict(X_test))
   TP = cm[0][0]
   TN = cm[1][1]
   FN = cm[1][0]
   FP = cm[0][1]
print(cm)
print('Testing Accuracy = ', (TP + TN)/(TP + TN + FN + FP))
print()

# testing the models/result

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

for i in range(len(model)):
    print("Model",i)
    print(classification_report(Y_test,model[i].predict(X_test)))
    print('Accuracy : ',accuracy_score(Y_test,model[i].predict(X_test)))

# prediction of random-forest
pred=model[1].predict(X_test)
print('Predicted values:')
print(pred)
print('Actual values:')
print(Y_test)